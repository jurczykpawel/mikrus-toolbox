#!/bin/bash

# Mikrus Toolbox - Crawl4AI
# AI-powered web crawler and scraper with REST API.
# Extract structured data from any website using LLMs.
# https://github.com/unclecode/crawl4ai
# Author: PaweÅ‚ (Lazy Engineer)
#
# IMAGE_SIZE_MB=2500  # unclecode/crawl4ai:latest (Chromium + Python + ML deps)
#
# âš ï¸  UWAGA: Ta aplikacja wymaga minimum 2GB RAM (Mikrus 2.0+)!
#     Crawl4AI uruchamia headless Chromium do crawlowania stron.
#     Na Mikrus 1.0 (1GB RAM) moÅ¼e powodowaÄ‡ zawieszenie serwera.

set -e

APP_NAME="crawl4ai"
STACK_DIR="/opt/stacks/$APP_NAME"
PORT=${PORT:-8000}

echo "--- ğŸ•·ï¸ Crawl4AI Setup ---"
echo "AI-powered web crawler z REST API."
echo ""

# SprawdÅº dostÄ™pny RAM - WYMAGANE minimum 2GB!
TOTAL_RAM=$(free -m 2>/dev/null | awk '/^Mem:/ {print $2}' || echo "0")

if [ "$TOTAL_RAM" -gt 0 ] && [ "$TOTAL_RAM" -lt 1800 ]; then
    echo ""
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘  âŒ BÅÄ„D: Za maÅ‚o RAM dla Crawl4AI!                          â•‘"
    echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
    echo "â•‘  TwÃ³j serwer: ${TOTAL_RAM}MB RAM                             â•‘"
    echo "â•‘  Wymagane:    2048MB RAM (Mikrus 2.0+)                       â•‘"
    echo "â•‘                                                              â•‘"
    echo "â•‘  Crawl4AI uruchamia headless Chromium (~1-1.5GB RAM).        â•‘"
    echo "â•‘  Na Mikrus 1.0 zawiesza serwer!                             â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    exit 1
fi

# Domain
if [ -n "$DOMAIN" ]; then
    echo "âœ… Domena: $DOMAIN"
else
    echo "âš ï¸  Brak domeny - uÅ¼yj --domain=... lub dostÄ™p przez SSH tunnel"
fi

# Generuj API token
CRAWL4AI_API_TOKEN=$(openssl rand -hex 32)

sudo mkdir -p "$STACK_DIR"
cd "$STACK_DIR"

# Zapisz token
echo "$CRAWL4AI_API_TOKEN" | sudo tee .api_token > /dev/null
sudo chmod 600 .api_token
echo "âœ… API token wygenerowany i zapisany"

cat <<EOF | sudo tee docker-compose.yaml > /dev/null
services:
  crawl4ai:
    image: unclecode/crawl4ai:latest
    restart: always
    ports:
      - "$PORT:11235"
    environment:
      - CRAWL4AI_API_TOKEN=$CRAWL4AI_API_TOKEN
    shm_size: "1g"
    deploy:
      resources:
        limits:
          memory: 1536M
EOF

sudo docker compose up -d

# Health check - Chromium potrzebuje duÅ¼o czasu na start
echo "â³ Czekam na uruchomienie Crawl4AI (~60-90s, Chromium siÄ™ Å‚aduje)..."
source /opt/mikrus-toolbox/lib/health-check.sh 2>/dev/null || true
if type wait_for_healthy &>/dev/null; then
    wait_for_healthy "$APP_NAME" "$PORT" 90 || { echo "âŒ Instalacja nie powiodÅ‚a siÄ™!"; exit 1; }
else
    for i in $(seq 1 9); do
        sleep 10
        if curl -sf "http://localhost:$PORT" > /dev/null 2>&1 || curl -sf "http://localhost:$PORT/health" > /dev/null 2>&1; then
            echo "âœ… Crawl4AI dziaÅ‚a (po $((i*10))s)"
            break
        fi
        echo "   ... $((i*10))s"
        if [ "$i" -eq 9 ]; then
            echo "âŒ Kontener nie wystartowaÅ‚ w 90s!"
            sudo docker compose logs --tail 30
            exit 1
        fi
    done
fi

echo ""
if [ -n "$DOMAIN" ]; then
    echo "ğŸ”— API dostÄ™pne pod: https://$DOMAIN"
else
    echo "ğŸ”— DostÄ™p przez SSH tunnel: ssh -L $PORT:localhost:$PORT <server>"
fi
echo ""
echo "ğŸ”‘ API Token: $CRAWL4AI_API_TOKEN"
echo "   Zapisany w: $STACK_DIR/.api_token"
echo ""
echo "ğŸ“‹ PrzykÅ‚ad uÅ¼ycia:"
echo "   curl -X POST http://localhost:$PORT/crawl \\"
echo "     -H 'Authorization: Bearer $CRAWL4AI_API_TOKEN' \\"
echo "     -H 'Content-Type: application/json' \\"
echo "     -d '{\"urls\": [\"https://example.com\"]}'"
